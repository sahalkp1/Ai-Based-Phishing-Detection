{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10.0"},
  "colab": {"provenance": [], "gpuType": "T4"},
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "md-title",
   "source": [
    "# ðŸ›¡ï¸ Phishing Email Detection â€” NLP Module\n",
    "### DistilBERT Fine-Tuning | Mini Project Phase 3\n",
    "---\n",
    "âš ï¸ **Enable GPU FIRST before running anything!**\n",
    "```\n",
    "Runtime â†’ Change runtime type â†’ T4 GPU â†’ Save\n",
    "```\n",
    "ðŸ“‚ **Dataset:** `Phishing_Email.csv`\n",
    "- 18,650 emails\n",
    "- Columns: `Email Text`, `Email Type`\n",
    "- Labels: `Safe Email` = 0, `Phishing Email` = 1\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "md-s1",
   "source": ["## âœ… Step 1 â€” Check GPU & Install Libraries"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "check-gpu",
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('âœ… GPU ready:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('âŒ No GPU detected!')\n",
    "    print('   Fix: Runtime â†’ Change runtime type â†’ T4 GPU â†’ Save')\n",
    "    print('   Then: Runtime â†’ Restart and run all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "install",
   "outputs": [],
   "source": [
    "!pip install transformers scikit-learn seaborn -q\n",
    "print('âœ… Libraries installed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "md-s2",
   "source": ["## âœ… Step 2 â€” Upload Dataset"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "upload",
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "print('ðŸ“‚ File picker will appear below...')\n",
    "print('   Select your Phishing_Email.csv and wait for upload to complete.')\n",
    "uploaded = files.upload()\n",
    "print('\\nâœ… Uploaded:', list(uploaded.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "md-s3",
   "source": ["## âœ… Step 3 â€” Load & Explore Data"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "load-data",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load â€” drop the unnamed index column\n",
    "df = pd.read_csv('Phishing_Email.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "\n",
    "print('Shape:', df.shape)\n",
    "print('Columns:', df.columns.tolist())\n",
    "print('\\nLabel distribution:')\n",
    "print(df['Email Type'].value_counts())\n",
    "print('\\nSample rows:')\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "visualise",
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
    "\n",
    "# Class balance\n",
    "counts = df['Email Type'].value_counts()\n",
    "colors = ['steelblue', 'tomato']\n",
    "axes[0].bar(counts.index, counts.values, color=colors, edgecolor='black')\n",
    "axes[0].set_title('Class Distribution', fontsize=13)\n",
    "axes[0].set_ylabel('Count')\n",
    "for i, v in enumerate(counts.values):\n",
    "    axes[0].text(i, v + 80, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Email length distribution\n",
    "df['text_length'] = df['Email Text'].fillna('').apply(len)\n",
    "for label, color in [('Safe Email', 'steelblue'), ('Phishing Email', 'tomato')]:\n",
    "    axes[1].hist(\n",
    "        df[df['Email Type'] == label]['text_length'].clip(upper=5000),\n",
    "        bins=50, alpha=0.6, color=color, label=label\n",
    "    )\n",
    "axes[1].set_title('Email Length Distribution', fontsize=13)\n",
    "axes[1].set_xlabel('Character Count')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "md-s4",
   "source": ["## âœ… Step 4 â€” Clean & Split Data"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "clean",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop missing and duplicate rows\n",
    "df = df.dropna(subset=['Email Text', 'Email Type'])\n",
    "df = df.drop_duplicates(subset='Email Text')\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Convert labels: Phishing Email = 1, Safe Email = 0\n",
    "df['label'] = (df['Email Type'] == 'Phishing Email').astype(int)\n",
    "\n",
    "# Truncate very long emails (DistilBERT max is 512 tokens)\n",
    "df['Email Text'] = df['Email Text'].str[:1500]\n",
    "\n",
    "print(f'Total emails after cleaning: {len(df)}')\n",
    "print(f'Safe     (0): {(df[\"label\"]==0).sum()}')\n",
    "print(f'Phishing (1): {(df[\"label\"]==1).sum()}')\n",
    "\n",
    "# 80 / 10 / 10 split  â€” stratified to keep label balance in each split\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "val_df, test_df   = train_test_split(\n",
    "    temp_df, test_size=0.5, random_state=42, stratify=temp_df['label'])\n",
    "\n",
    "print(f'\\nTrain: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "md-s5",
   "source": ["## âœ… Step 5 â€” Tokenize with DistilBERT"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "tokenize",
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "print('Loading DistilBERT tokenizer...')\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "MAX_LEN = 256  # 256 tokens is enough for emails; saves GPU memory\n",
    "\n",
    "def tokenize(texts):\n",
    "    return tokenizer(\n",
    "        list(texts),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "print('Tokenizing train set...')\n",
    "train_enc = tokenize(train_df['Email Text'])\n",
    "print('Tokenizing val set...')\n",
    "val_enc   = tokenize(val_df['Email Text'])\n",
    "print('Tokenizing test set...')\n",
    "test_enc  = tokenize(test_df['Email Text'])\n",
    "print('\\nâœ… Tokenization complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "md-s6",
   "source": ["## âœ… Step 6 â€” Create PyTorch Dataset"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "dataset",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class EmailDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels.reset_index(drop=True).tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: v[idx] for k, v in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "train_dataset = EmailDataset(train_enc, train_df['label'])\n",
    "val_dataset   = EmailDataset(val_enc,   val_df['label'])\n",
    "test_dataset  = EmailDataset(test_enc,  test_df['label'])\n",
    "\n",
    "print(f'âœ… Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "md-s7",
   "source": [
    "## âœ… Step 7 â€” Load DistilBERT & Fine-Tune\n",
    "> â±ï¸ **~15â€“25 minutes on T4 GPU. Do NOT close the browser tab!**\n",
    "> \n",
    "> ðŸ’¡ If you get `CUDA out of memory` error â†’ change `per_device_train_batch_size=16` to `8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "load-model",
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Loading DistilBERT model...')\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=2  # 0 = Safe Email, 1 = Phishing Email\n",
    ")\n",
    "model.to(device)\n",
    "print(f'âœ… Model loaded on: {device}')\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds  = pred.predictions.argmax(-1)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy':  round(acc, 4),\n",
    "        'f1':        round(f1, 4),\n",
    "        'precision': round(p, 4),\n",
    "        'recall':    round(r, 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "train",
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,  # â† change to 8 if CUDA out of memory\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    logging_steps=50,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print('ðŸš€ Training started...')\n",
    "print('You will see Epoch 1/3 â†’ 2/3 â†’ 3/3 progress bars below.')\n",
    "print('Expected time: ~15â€“25 mins on T4 GPU')\n",
    "print('-' * 50)\n",
    "trainer.train()\n",
    "print('\\nâœ… Training complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "md-s8",
   "source": ["## âœ… Step 8 â€” Evaluate on Test Set"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "evaluate",
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print('Running predictions on test set...')\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds  = predictions.predictions.argmax(-1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "print('\\n' + '='*50)\n",
    "print('        CLASSIFICATION REPORT')\n",
    "print('='*50)\n",
    "print(classification_report(\n",
    "    labels, preds,\n",
    "    target_names=['Safe Email', 'Phishing Email']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "confusion",
   "outputs": [],
   "source": [
    "cm = confusion_matrix(labels, preds)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt='d', cmap='Blues',\n",
    "    xticklabels=['Safe Email', 'Phishing Email'],\n",
    "    yticklabels=['Safe Email', 'Phishing Email'],\n",
    "    annot_kws={'size': 14}\n",
    ")\n",
    "plt.title('Confusion Matrix â€” Test Set', fontsize=14)\n",
    "plt.ylabel('Actual Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f'âœ… Phishing correctly caught:       {tp}')\n",
    "print(f'âœ… Safe emails correctly identified: {tn}')\n",
    "print(f'âš ï¸  Phishing missed (false negative): {fn}')\n",
    "print(f'âš ï¸  Safe wrongly flagged (false pos): {fp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "md-s9",
   "source": [
    "## âœ… Step 9 â€” Live Prediction Function\n",
    "> ðŸŽ¯ Use this for your mini project demo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "predict",
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_email(text):\n",
    "    \"\"\"Predict if an email is Safe or Phishing.\"\"\"\n",
    "    model.eval()\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=True\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    probs      = F.softmax(outputs.logits, dim=-1)\n",
    "    predicted  = probs.argmax().item()\n",
    "    confidence = probs.max().item()\n",
    "    result     = 'ðŸš¨ PHISHING EMAIL' if predicted == 1 else 'âœ… SAFE EMAIL'\n",
    "\n",
    "    short = text[:80] + '...' if len(text) > 80 else text\n",
    "    print(f'Input:      \"{short}\"')\n",
    "    print(f'Prediction: {result}')\n",
    "    print(f'Confidence: {confidence:.2%}')\n",
    "    print(f'Safe: {probs[0][0].item():.2%}  |  Phishing: {probs[0][1].item():.2%}')\n",
    "    print('-' * 65)\n",
    "\n",
    "# â”€â”€ Demo predictions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print('='*65)\n",
    "print('          LIVE PHISHING DETECTION DEMO')\n",
    "print('='*65)\n",
    "\n",
    "predict_email(\n",
    "    \"Your account has been suspended. Click here immediately to verify \"\n",
    "    \"your identity and avoid permanent closure of your account.\"\n",
    ")\n",
    "\n",
    "predict_email(\n",
    "    \"Hi team, please find the Q3 meeting notes attached. \"\n",
    "    \"Let me know if you have any questions.\"\n",
    ")\n",
    "\n",
    "predict_email(\n",
    "    \"Congratulations! You have been selected for a $1000 Amazon gift card. \"\n",
    "    \"Claim your prize now before it expires!\"\n",
    ")\n",
    "\n",
    "predict_email(\n",
    "    \"Dear customer, your PayPal account has been limited. \"\n",
    "    \"Please update your billing information to restore full access.\"\n",
    ")\n",
    "\n",
    "predict_email(\n",
    "    \"Hey, are you joining us for lunch today? \"\n",
    "    \"We are thinking of trying the new place on 5th street.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "custom-test",
   "outputs": [],
   "source": [
    "# â”€â”€ Try YOUR OWN email text here â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "my_email = \"\"\"Type or paste any email text here and run this cell!\"\"\"\n",
    "\n",
    "predict_email(my_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "md-s10",
   "source": ["## âœ… Step 10 â€” Save & Download the Model"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "save",
   "outputs": [],
   "source": [
    "# Save model + tokenizer\n",
    "model.save_pretrained('./phishing_detector_model')\n",
    "tokenizer.save_pretrained('./phishing_detector_model')\n",
    "print('âœ… Model saved to ./phishing_detector_model/')\n",
    "\n",
    "# Zip and download\n",
    "!zip -r phishing_detector_model.zip ./phishing_detector_model\n",
    "\n",
    "from google.colab import files\n",
    "files.download('phishing_detector_model.zip')\n",
    "print('âœ… Download started â€” check your browser downloads folder!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "md-done",
   "source": [
    "---\n",
    "## ðŸŽ‰ Phase 3 Complete!\n",
    "\n",
    "| Step | Task | Status |\n",
    "|------|------|--------|\n",
    "| 1 | GPU check + install libraries | âœ… |\n",
    "| 2 | Upload `Phishing_Email.csv` | âœ… |\n",
    "| 3 | Load & explore (18,650 emails) | âœ… |\n",
    "| 4 | Clean + 80/10/10 split | âœ… |\n",
    "| 5 | DistilBERT tokenization | âœ… |\n",
    "| 6 | PyTorch dataset creation | âœ… |\n",
    "| 7 | Fine-tune 3 epochs (~20 mins) | âœ… |\n",
    "| 8 | Evaluate + confusion matrix | âœ… |\n",
    "| 9 | Live prediction demo | âœ… |\n",
    "| 10 | Save & download model | âœ… |\n",
    "\n",
    "**Expected results:**\n",
    "- Accuracy: ~97â€“98%\n",
    "- F1 Score: ~0.96â€“0.98\n",
    "\n",
    "---"
   ]
  }
 ]
}
